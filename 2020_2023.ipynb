{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "weatherData = pd.read_csv('2020-2023/daily_data_combined_2020_to_2023.csv')\n",
    "weatherData_2010_2019 = pd.read_csv('2010-2019/daily_data_combined_2010_to_2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['city_name', 'datetime', 'weather_code', 'temperature_2m_max',\n",
      "       'temperature_2m_min', 'temperature_2m_mean', 'apparent_temperature_max',\n",
      "       'apparent_temperature_min', 'apparent_temperature_mean', 'sunrise',\n",
      "       'sunset', 'daylight_duration', 'sunshine_duration', 'precipitation_sum',\n",
      "       'rain_sum', 'snowfall_sum', 'precipitation_hours', 'wind_speed_10m_max',\n",
      "       'wind_gusts_10m_max', 'wind_direction_10m_dominant',\n",
      "       'shortwave_radiation_sum', 'et0_fao_evapotranspiration'],\n",
      "      dtype='object')\n",
      "Index(['city_name', 'latitude', 'longitude', 'datetime', 'weather_code',\n",
      "       'temperature_2m_max', 'temperature_2m_min', 'temperature_2m_mean',\n",
      "       'apparent_temperature_max', 'apparent_temperature_min',\n",
      "       'apparent_temperature_mean', 'sunrise', 'sunset', 'daylight_duration',\n",
      "       'sunshine_duration', 'precipitation_sum', 'rain_sum', 'snowfall_sum',\n",
      "       'precipitation_hours', 'wind_speed_10m_max', 'wind_gusts_10m_max',\n",
      "       'wind_direction_10m_dominant', 'shortwave_radiation_sum',\n",
      "       'et0_fao_evapotranspiration'],\n",
      "      dtype='object')\n",
      "{'latitude', 'longitude'}\n"
     ]
    }
   ],
   "source": [
    "print(weatherData.columns)\n",
    "print(weatherData_2010_2019.columns)\n",
    "columns_not_in_weatherData = set(weatherData_2010_2019.columns) - set(weatherData.columns)\n",
    "print(columns_not_in_weatherData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = pd.read_csv('2020-2023/cities.csv')\n",
    "# Merge the weatherData with cities to include latitude and longitude\n",
    "weatherData = weatherData.merge(cities, on='city_name', how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the datetime column to a datetime object\n",
    "weatherData['datetime'] = pd.to_datetime(weatherData['datetime'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.01      0.02       103\n",
      "         1.0       0.64      0.44      0.52      1294\n",
      "         2.0       0.50      0.05      0.09      1150\n",
      "         3.0       0.70      0.72      0.71      1380\n",
      "        51.0       0.76      0.96      0.84     10178\n",
      "        53.0       0.68      0.29      0.41      6111\n",
      "        55.0       0.00      0.00      0.00      2409\n",
      "        61.0       0.34      0.36      0.35      6533\n",
      "        63.0       0.57      0.84      0.68     11527\n",
      "        65.0       0.73      0.52      0.61      2853\n",
      "\n",
      "    accuracy                           0.61     43538\n",
      "   macro avg       0.59      0.42      0.42     43538\n",
      "weighted avg       0.58      0.61      0.57     43538\n",
      "\n",
      "Data types per column:\n",
      "city_name                       object\n",
      "datetime                        object\n",
      "weather_code                   float64\n",
      "temperature_2m_max             float64\n",
      "temperature_2m_min             float64\n",
      "temperature_2m_mean            float64\n",
      "apparent_temperature_max       float64\n",
      "apparent_temperature_min       float64\n",
      "apparent_temperature_mean      float64\n",
      "sunrise                          int32\n",
      "sunset                           int32\n",
      "daylight_duration              float64\n",
      "sunshine_duration              float64\n",
      "precipitation_sum              float64\n",
      "rain_sum                       float64\n",
      "snowfall_sum                   float64\n",
      "precipitation_hours            float64\n",
      "wind_speed_10m_max             float64\n",
      "wind_gusts_10m_max             float64\n",
      "wind_direction_10m_dominant    float64\n",
      "shortwave_radiation_sum        float64\n",
      "et0_fao_evapotranspiration     float64\n",
      "latitude                       float64\n",
      "longitude                      float64\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\GITHUB\\philippine-weather-Patterns\\.env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\GITHUB\\philippine-weather-Patterns\\.env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\GITHUB\\philippine-weather-Patterns\\.env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Function to convert time to minutes since midnight\n",
    "def time_to_minutes(time_str):\n",
    "    time_obj = pd.to_datetime(time_str, format='%Y-%m-%dT%H:%M', errors='coerce')\n",
    "    return time_obj.dt.hour * 60 + time_obj.dt.minute\n",
    "\n",
    "# Convert sunrise and sunset columns to numerical values\n",
    "weatherData['sunrise'] = time_to_minutes(weatherData['sunrise'])\n",
    "weatherData['sunset'] = time_to_minutes(weatherData['sunset'])\n",
    "\n",
    "# Separate features and label\n",
    "X = weatherData.drop(columns=['weather_code'])\n",
    "y = weatherData['weather_code']\n",
    "\n",
    "# Identify numerical and categorical columns\n",
    "numerical_cols = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Preprocessing for numerical data: impute missing values and scale\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Preprocessing for categorical data: impute missing values and one-hot encode\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Create a preprocessing and training pipeline\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', SGDClassifier())\n",
    "])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print data types per column\n",
    "print(\"Data types per column:\")\n",
    "print(weatherData.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from pcaModels\\GradientBoostingClassifier.joblib\n",
      "Loaded model from pcaModels\\KNeighborsClassifier.joblib\n",
      "Loaded model from pcaModels\\LinearSVC.joblib\n",
      "Loaded model from pcaModels\\pca.joblib\n",
      "Loaded model from pcaModels\\preprocessor.joblib\n",
      "Loaded model from pcaModels\\RandomForestClassifier.joblib\n",
      "Loaded model from pcaModels\\SGDClassifier.joblib\n",
      "Loaded model from pcaModels\\SVC.joblib\n",
      "Model 1 is not a Pipeline.\n",
      "Model 1 is of type <class 'sklearn.ensemble._gb.GradientBoostingClassifier'>\n",
      "Model 2 is of type <class 'sklearn.neighbors._classification.KNeighborsClassifier'>\n",
      "Model 3 is of type <class 'sklearn.svm._classes.LinearSVC'>\n",
      "Model 4 is of type <class 'sklearn.decomposition._pca.PCA'>\n",
      "Model 5 is of type <class 'sklearn.compose._column_transformer.ColumnTransformer'>\n",
      "Model 6 is of type <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Model 7 is of type <class 'sklearn.linear_model._stochastic_gradient.SGDClassifier'>\n",
      "Model 8 is of type <class 'sklearn.svm._classes.SVC'>\n",
      "Model 2 is not a Pipeline.\n",
      "Model 1 is of type <class 'sklearn.ensemble._gb.GradientBoostingClassifier'>\n",
      "Model 2 is of type <class 'sklearn.neighbors._classification.KNeighborsClassifier'>\n",
      "Model 3 is of type <class 'sklearn.svm._classes.LinearSVC'>\n",
      "Model 4 is of type <class 'sklearn.decomposition._pca.PCA'>\n",
      "Model 5 is of type <class 'sklearn.compose._column_transformer.ColumnTransformer'>\n",
      "Model 6 is of type <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Model 7 is of type <class 'sklearn.linear_model._stochastic_gradient.SGDClassifier'>\n",
      "Model 8 is of type <class 'sklearn.svm._classes.SVC'>\n",
      "Model 3 is not a Pipeline.\n",
      "Model 1 is of type <class 'sklearn.ensemble._gb.GradientBoostingClassifier'>\n",
      "Model 2 is of type <class 'sklearn.neighbors._classification.KNeighborsClassifier'>\n",
      "Model 3 is of type <class 'sklearn.svm._classes.LinearSVC'>\n",
      "Model 4 is of type <class 'sklearn.decomposition._pca.PCA'>\n",
      "Model 5 is of type <class 'sklearn.compose._column_transformer.ColumnTransformer'>\n",
      "Model 6 is of type <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Model 7 is of type <class 'sklearn.linear_model._stochastic_gradient.SGDClassifier'>\n",
      "Model 8 is of type <class 'sklearn.svm._classes.SVC'>\n",
      "Model 4 is not a Pipeline.\n",
      "Model 1 is of type <class 'sklearn.ensemble._gb.GradientBoostingClassifier'>\n",
      "Model 2 is of type <class 'sklearn.neighbors._classification.KNeighborsClassifier'>\n",
      "Model 3 is of type <class 'sklearn.svm._classes.LinearSVC'>\n",
      "Model 4 is of type <class 'sklearn.decomposition._pca.PCA'>\n",
      "Model 5 is of type <class 'sklearn.compose._column_transformer.ColumnTransformer'>\n",
      "Model 6 is of type <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Model 7 is of type <class 'sklearn.linear_model._stochastic_gradient.SGDClassifier'>\n",
      "Model 8 is of type <class 'sklearn.svm._classes.SVC'>\n",
      "Model 5 is not a Pipeline.\n",
      "Model 1 is of type <class 'sklearn.ensemble._gb.GradientBoostingClassifier'>\n",
      "Model 2 is of type <class 'sklearn.neighbors._classification.KNeighborsClassifier'>\n",
      "Model 3 is of type <class 'sklearn.svm._classes.LinearSVC'>\n",
      "Model 4 is of type <class 'sklearn.decomposition._pca.PCA'>\n",
      "Model 5 is of type <class 'sklearn.compose._column_transformer.ColumnTransformer'>\n",
      "Model 6 is of type <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Model 7 is of type <class 'sklearn.linear_model._stochastic_gradient.SGDClassifier'>\n",
      "Model 8 is of type <class 'sklearn.svm._classes.SVC'>\n",
      "Model 6 is not a Pipeline.\n",
      "Model 1 is of type <class 'sklearn.ensemble._gb.GradientBoostingClassifier'>\n",
      "Model 2 is of type <class 'sklearn.neighbors._classification.KNeighborsClassifier'>\n",
      "Model 3 is of type <class 'sklearn.svm._classes.LinearSVC'>\n",
      "Model 4 is of type <class 'sklearn.decomposition._pca.PCA'>\n",
      "Model 5 is of type <class 'sklearn.compose._column_transformer.ColumnTransformer'>\n",
      "Model 6 is of type <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Model 7 is of type <class 'sklearn.linear_model._stochastic_gradient.SGDClassifier'>\n",
      "Model 8 is of type <class 'sklearn.svm._classes.SVC'>\n",
      "Model 7 is not a Pipeline.\n",
      "Model 1 is of type <class 'sklearn.ensemble._gb.GradientBoostingClassifier'>\n",
      "Model 2 is of type <class 'sklearn.neighbors._classification.KNeighborsClassifier'>\n",
      "Model 3 is of type <class 'sklearn.svm._classes.LinearSVC'>\n",
      "Model 4 is of type <class 'sklearn.decomposition._pca.PCA'>\n",
      "Model 5 is of type <class 'sklearn.compose._column_transformer.ColumnTransformer'>\n",
      "Model 6 is of type <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Model 7 is of type <class 'sklearn.linear_model._stochastic_gradient.SGDClassifier'>\n",
      "Model 8 is of type <class 'sklearn.svm._classes.SVC'>\n",
      "Model 8 is not a Pipeline.\n",
      "Model 1 is of type <class 'sklearn.ensemble._gb.GradientBoostingClassifier'>\n",
      "Model 2 is of type <class 'sklearn.neighbors._classification.KNeighborsClassifier'>\n",
      "Model 3 is of type <class 'sklearn.svm._classes.LinearSVC'>\n",
      "Model 4 is of type <class 'sklearn.decomposition._pca.PCA'>\n",
      "Model 5 is of type <class 'sklearn.compose._column_transformer.ColumnTransformer'>\n",
      "Model 6 is of type <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Model 7 is of type <class 'sklearn.linear_model._stochastic_gradient.SGDClassifier'>\n",
      "Model 8 is of type <class 'sklearn.svm._classes.SVC'>\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the models from pcaModels\n",
    "# Load all models from the pcaModels folder\n",
    "\n",
    "pcaModels = []\n",
    "models_folder = 'pcaModels'\n",
    "for model_file in os.listdir(models_folder):\n",
    "    if model_file.endswith('.joblib'):\n",
    "        model_path = os.path.join(models_folder, model_file)\n",
    "        pcaModels.append(joblib.load(model_path))\n",
    "        print(f\"Loaded model from {model_path}\")\n",
    "\n",
    "for i, model in enumerate(pcaModels):\n",
    "    if isinstance(model, Pipeline):\n",
    "        preprocessor = model.named_steps['preprocessor']\n",
    "        num_features = preprocessor.transformers_[0][2]\n",
    "        cat_features = preprocessor.transformers_[1][2]\n",
    "        all_features = list(num_features) + list(preprocessor.named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(cat_features))\n",
    "        print(f\"Features for model {i+1}: {all_features}\")\n",
    "    else:\n",
    "        print(f\"Model {i+1} is not a Pipeline.\")\n",
    "\n",
    "        # Since none of the models are pipelines, we will just print the model types\n",
    "        for i, model in enumerate(pcaModels):\n",
    "            print(f\"Model {i+1} is of type {type(model)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Specifying the columns using strings is only supported for dataframes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32md:\\GITHUB\\philippine-weather-Patterns\\.env\\Lib\\site-packages\\sklearn\\utils\\_indexing.py:341\u001b[0m, in \u001b[0;36m_get_column_indices\u001b[1;34m(X, key)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 341\u001b[0m     all_columns \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'csr_matrix' object has no attribute 'columns'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Train each pipeline model\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pipeline \u001b[38;5;129;01min\u001b[39;00m pipelineModels:\n\u001b[1;32m---> 15\u001b[0m     \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Make predictions with each pipeline model\u001b[39;00m\n\u001b[0;32m     18\u001b[0m pipeline_predictions \u001b[38;5;241m=\u001b[39m [pipeline\u001b[38;5;241m.\u001b[39mpredict(X_test\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcity_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m'\u001b[39m])) \u001b[38;5;28;01mfor\u001b[39;00m pipeline \u001b[38;5;129;01min\u001b[39;00m pipelineModels]\n",
      "File \u001b[1;32md:\\GITHUB\\philippine-weather-Patterns\\.env\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\GITHUB\\philippine-weather-Patterns\\.env\\Lib\\site-packages\\sklearn\\pipeline.py:660\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    654\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    655\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_metadata_for_step(\n\u001b[0;32m    656\u001b[0m             step_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    657\u001b[0m             step_params\u001b[38;5;241m=\u001b[39mrouted_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]],\n\u001b[0;32m    658\u001b[0m             all_params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    659\u001b[0m         )\n\u001b[1;32m--> 660\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32md:\\GITHUB\\philippine-weather-Patterns\\.env\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:946\u001b[0m, in \u001b[0;36mColumnTransformer.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    943\u001b[0m _raise_for_params(params, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    944\u001b[0m \u001b[38;5;66;03m# we use fit_transform to make sure to set sparse_output_ (for which we\u001b[39;00m\n\u001b[0;32m    945\u001b[0m \u001b[38;5;66;03m# need the transformed data) to have consistent output type in predict\u001b[39;00m\n\u001b[1;32m--> 946\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    947\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32md:\\GITHUB\\philippine-weather-Patterns\\.env\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    322\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    323\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    324\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    325\u001b[0m         )\n",
      "File \u001b[1;32md:\\GITHUB\\philippine-weather-Patterns\\.env\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\GITHUB\\philippine-weather-Patterns\\.env\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:992\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_transformers()\n\u001b[0;32m    990\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(X)\n\u001b[1;32m--> 992\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_column_callables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    993\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_remainder(X)\n\u001b[0;32m    995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _routing_enabled():\n",
      "File \u001b[1;32md:\\GITHUB\\philippine-weather-Patterns\\.env\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:551\u001b[0m, in \u001b[0;36mColumnTransformer._validate_column_callables\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    549\u001b[0m         columns \u001b[38;5;241m=\u001b[39m columns(X)\n\u001b[0;32m    550\u001b[0m     all_columns\u001b[38;5;241m.\u001b[39mappend(columns)\n\u001b[1;32m--> 551\u001b[0m     transformer_to_input_indices[name] \u001b[38;5;241m=\u001b[39m \u001b[43m_get_column_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_columns \u001b[38;5;241m=\u001b[39m all_columns\n\u001b[0;32m    554\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transformer_to_input_indices \u001b[38;5;241m=\u001b[39m transformer_to_input_indices\n",
      "File \u001b[1;32md:\\GITHUB\\philippine-weather-Patterns\\.env\\Lib\\site-packages\\sklearn\\utils\\_indexing.py:343\u001b[0m, in \u001b[0;36m_get_column_indices\u001b[1;34m(X, key)\u001b[0m\n\u001b[0;32m    341\u001b[0m     all_columns \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m--> 343\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    344\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpecifying the columns using strings is only supported for dataframes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    345\u001b[0m     )\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    347\u001b[0m     columns \u001b[38;5;241m=\u001b[39m [key]\n",
      "\u001b[1;31mValueError\u001b[0m: Specifying the columns using strings is only supported for dataframes."
     ]
    }
   ],
   "source": [
    "# Convert each model in pcaModels to a pipeline\n",
    "pipelineModels = []\n",
    "for model in pcaModels:\n",
    "    if not isinstance(model, Pipeline):\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', model)\n",
    "        ])\n",
    "        pipelineModels.append(pipeline)\n",
    "    else:\n",
    "        pipelineModels.append(model)\n",
    "\n",
    "# Train each pipeline model\n",
    "for pipeline in pipelineModels:\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions with each pipeline model\n",
    "pipeline_predictions = [pipeline.predict(X_test.drop(columns=['city_name', 'datetime'])) for pipeline in pipelineModels]\n",
    "\n",
    "# Calculate the deviations for each pipeline model\n",
    "pipeline_deviations = [np.abs(pred - y_test.values) for pred in pipeline_predictions]\n",
    "\n",
    "# Print the deviations\n",
    "for i, deviation in enumerate(pipeline_deviations):\n",
    "    print(f\"Deviations for pipeline model {i+1}: {deviation}\")\n",
    "\n",
    "# Plot the deviations for each pipeline model\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i, deviation in enumerate(pipeline_deviations):\n",
    "    plt.plot(deviation, label=f'Pipeline Model {i+1}')\n",
    "\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Deviation')\n",
    "plt.title('Deviations of Predictions from Actual Weather Code')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from pcaModels\\GradientBoostingClassifier.joblib\n",
      "Loaded model from pcaModels\\KNeighborsClassifier.joblib\n",
      "Loaded model from pcaModels\\LinearSVC.joblib\n",
      "Loaded model from pcaModels\\pca.joblib\n",
      "Loaded model from pcaModels\\preprocessor.joblib\n",
      "Loaded model from pcaModels\\RandomForestClassifier.joblib\n",
      "Loaded model from pcaModels\\SGDClassifier.joblib\n",
      "Loaded model from pcaModels\\SVC.joblib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\GITHUB\\philippine-weather-Patterns\\.env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2732: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 19 features, but GradientBoostingClassifier is expecting 10 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m features \u001b[38;5;241m=\u001b[39m weatherData[columns_to_include]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Predict the weather_code using each model in pcaModels\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m predictions \u001b[38;5;241m=\u001b[39m [\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m pcaModels]\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Calculate the deviations for each model\u001b[39;00m\n\u001b[0;32m     33\u001b[0m deviations \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mabs(pred \u001b[38;5;241m-\u001b[39m weatherData[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweather_code\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues) \u001b[38;5;28;01mfor\u001b[39;00m pred \u001b[38;5;129;01min\u001b[39;00m predictions]\n",
      "File \u001b[1;32md:\\GITHUB\\philippine-weather-Patterns\\.env\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:1618\u001b[0m, in \u001b[0;36mGradientBoostingClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1603\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m   1604\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Predict class for X.\u001b[39;00m\n\u001b[0;32m   1605\u001b[0m \n\u001b[0;32m   1606\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1616\u001b[0m \u001b[38;5;124;03m        The predicted values.\u001b[39;00m\n\u001b[0;32m   1617\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1618\u001b[0m     raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1619\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m raw_predictions\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:  \u001b[38;5;66;03m# decision_function already squeezed it\u001b[39;00m\n\u001b[0;32m   1620\u001b[0m         encoded_classes \u001b[38;5;241m=\u001b[39m (raw_predictions \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[1;32md:\\GITHUB\\philippine-weather-Patterns\\.env\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:1571\u001b[0m, in \u001b[0;36mGradientBoostingClassifier.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m   1553\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the decision function of ``X``.\u001b[39;00m\n\u001b[0;32m   1554\u001b[0m \n\u001b[0;32m   1555\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1569\u001b[0m \u001b[38;5;124;03m        array of shape (n_samples,).\u001b[39;00m\n\u001b[0;32m   1570\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1571\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1572\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1573\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1574\u001b[0m     raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raw_predict(X)\n\u001b[0;32m   1575\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m raw_predictions\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32md:\\GITHUB\\philippine-weather-Patterns\\.env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2965\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2962\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m   2964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m-> 2965\u001b[0m     \u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32md:\\GITHUB\\philippine-weather-Patterns\\.env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2829\u001b[0m, in \u001b[0;36m_check_n_features\u001b[1;34m(estimator, X, reset)\u001b[0m\n\u001b[0;32m   2826\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   2828\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m-> 2829\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2830\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2831\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2832\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 19 features, but GradientBoostingClassifier is expecting 10 features as input."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Extract the features for prediction (excluding the target variable 'weather_code')\n",
    "columns_to_include = ['temperature_2m_max', 'temperature_2m_min', 'temperature_2m_mean', 'apparent_temperature_max', \n",
    "                      'apparent_temperature_min', 'apparent_temperature_mean', 'sunrise', 'sunset', 'daylight_duration', \n",
    "                      'sunshine_duration', 'precipitation_sum', 'rain_sum', 'snowfall_sum', 'precipitation_hours', \n",
    "                      'wind_speed_10m_max', 'wind_gusts_10m_max', 'wind_direction_10m_dominant', 'shortwave_radiation_sum', \n",
    "                      'et0_fao_evapotranspiration']\n",
    "\n",
    "# Filter columns that exist in weatherData\n",
    "columns_to_include = [col for col in columns_to_include if col in weatherData.columns]\n",
    "\n",
    "# Fill missing values with 0\n",
    "features = weatherData[columns_to_include].fillna(0)\n",
    "\n",
    "# Predict the weather_code using each model in pcaModels\n",
    "predictions = [model.predict(features) for model in pcaModels]\n",
    "\n",
    "# Calculate the deviations for each model\n",
    "deviations = [np.abs(pred - weatherData['weather_code'].values) for pred in predictions]\n",
    "\n",
    "# Print the deviations\n",
    "for i, deviation in enumerate(deviations):\n",
    "    print(f\"Deviations for model {i+1}: {deviation}\")\n",
    "\n",
    "# Plot the deviations for each model\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i, deviation in enumerate(deviations):\n",
    "    plt.plot(deviation, label=f'Model {i+1}')\n",
    "\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Deviation')\n",
    "plt.title('Deviations of Predictions from Actual Weather Code')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
